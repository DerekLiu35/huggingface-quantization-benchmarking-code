[MAIN-PROCESS][[36m2025-04-04 04:08:42,805[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:42,805[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:42,805[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:42,805[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:42,807[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:42,807[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:49,907[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [4] for process [3162900] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:08:49,907[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:49,929[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:50,336[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:50,337[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:50,338[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,627[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,627[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,627[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,628[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,628[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,628[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,628[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,628[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,629[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3162900[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,629[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,629[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,629[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:08:51,629[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:08:58,490[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Found process(es) [{3160379}] running on device(s) [4], other than the isolated process [3162900], the device isolation process [3163929] and their children [{3164033, 3164035, 3164038, 3164044, 3164046, 3164048, 3164050, 3164052, 3164181, 3164054, 3164056, 3164058, 3164060, 3164062, 3164064, 3163938, 3164066, 3163940, 3164580, 3163942, 3164068, 3163944, 3164070, 3163434, 3163946, 3164588, 3163948, 3164590, 3164072, 3164592, 3163950, 3164594, 3163952, 3164596, 3163954, 3164598, 3163956, 3164600, 3163958, 3164602, 3163960, 3164604, 3164606, 3164608, 3164610, 3164109, 3164029, 3164031}].[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:08:58,491[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Make sure no other process is running on the device(s) while benchmarking.[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:08:58,491[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Exiting device isolation process.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:08,911[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:08,911[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:08,912[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:08,912[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with pretrained weights[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:08,912[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading QuantizationMethod.TORCHAO-quantized model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:09:10,071[0m][[34maccelerate.utils.modeling[0m][[32mINFO[0m] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:29,792[0m][[34maccelerate.big_modeling[0m][[33mWARNING[0m] - Some parameters are on the meta device because they were offloaded to the cpu.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:30,391[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:30,394[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:30,495[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:30,495[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:31,938[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:11:31,963[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:11:38,484[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:11:38,484[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,525[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,526[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,526[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,526[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,529[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:13,529[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:22,035[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [4] for process [3174061] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:22,035[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:22,062[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:22,584[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:22,584[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:22,588[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,909[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,910[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,910[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,910[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,910[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3174061[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:23,911[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,462[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,463[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,463[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,466[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with pretrained weights[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,466[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading QuantizationMethod.TORCHAO-quantized model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,664[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:15:43,686[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:46,182[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:15:46,183[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,288[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,289[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,289[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,289[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,291[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:32,291[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:39,782[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [4] for process [3179487] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:17:39,782[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:39,804[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:40,205[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:40,206[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:40,207[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,489[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,489[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,489[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,490[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3179487[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,491[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,491[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,491[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:41,491[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:58,898[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:58,899[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:58,899[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:58,900[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:17:58,923[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:18:00,304[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:18:00,351[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,628[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,628[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `2,4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,628[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 2,4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,629[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,631[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:38,631[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:45,966[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [2,4] for process [3206128] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:30:45,967[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:45,989[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:46,395[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:46,395[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:46,396[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,687[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,688[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,688[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,688[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3206128[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [2, 4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 2 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,689[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:30:47,690[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:05,081[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:05,082[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:05,082[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:05,083[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:05,106[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:06,416[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:06,656[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,452[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,452[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,452[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,452[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,454[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:47,454[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:55,516[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [4] for process [3208753] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:31:55,516[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:55,539[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:56,139[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:56,139[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:56,141[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,582[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,583[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,583[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,583[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3208753[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,584[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:31:57,585[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:32:14,020[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:32:14,021[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:32:14,021[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:32:14,022[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with pretrained weights[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:32:14,022[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading QuantizationMethod.TORCHAO-quantized model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:09,147[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:09,150[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:09,452[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:09,452[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:11,145[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:35:11,167[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:35:12,425[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:35:12,467[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,671[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` was not specified, using all available GPUs.[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,671[0m][[34mbackend[0m][[33mWARNING[0m] - `device_ids` is now set to `2,4` based on system configuration.[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,671[0m][[34mbackend[0m][[32mINFO[0m] - CUDA_VISIBLE_DEVICES was set to 2,4.[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,671[0m][[34moptimum_benchmark.backends.pytorch.config[0m][[33mWARNING[0m] - `backend.quantization_scheme` is deprecated and will be removed in a future version. Please use `quantization_config.quant_method` instead.[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,673[0m][[34mprocess[0m][[32mINFO[0m] - Allocated process launcher[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:03,674[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Setting multiprocessing start method to spawn[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:11,189[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Isolating device(s) [2,4] for process [3243209] and its children[0m
[MAIN-PROCESS][[36m2025-04-04 04:44:11,189[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Executing action [warn] in case of violation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:11,212[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.6.0 available.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:11,619[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:11,619[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:11,620[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,891[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,892[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,892[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,892[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,892[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,892[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3243209[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [2, 4][0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 2 Pytorch CUDA devices[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:12,893[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:30,285[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:30,286[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing quantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:30,286[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Processing AutoQuantization config[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:30,287[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with pretrained weights[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:44:30,287[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading QuantizationMethod.TORCHAO-quantized model[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:45:18,500[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Found process(es) [{3246911}] running on device(s) [2,4], other than the isolated process [3243513], the device isolation process [3243513] and their children [{3243525, 3244294, 3243527, 3244296, 3243529, 3244298, 3243531, 3244300, 3243533, 3244302, 3243535, 3244304, 3243537, 3244306, 3243539, 3244308, 3243541, 3244310, 3244055, 3243543, 3243545, 3244312, 3244314, 3244316, 3244058, 3244318, 3244060, 3244320, 3244062, 3244322, 3244064, 3244324, 3244066, 3244326, 3244068, 3244328, 3244070, 3244330, 3244073, 3244332, 3244075, 3244334, 3244077, 3244336, 3244079, 3244338, 3244081, 3244340, 3244083, 3244085, 3244087, 3244089, 3244091, 3244093, 3244095, 3244097, 3244099, 3244101, 3244103, 3244105, 3244107, 3244109, 3244623, 3244111, 3244625, 3244113, 3244627, 3243348, 3244629, 3244405, 3244631, 3244115, 3244633, 3244117, 3244635, 3244119, 3244637, 3244121, 3244639, 3244407, 3244641, 3244643, 3243620, 3244645, 3243622, 3244647, 3243624, 3244649, 3243626, 3244651, 3243628, 3244653, 3243630, 3244655, 3243632, 3244657, 3243634, 3244659, 3243636, 3244661, 3243638, 3244663, 3243640, 3244665, 3243642, 3244667, 3243644, 3244669, 3243646, 3244671, 3243648, 3244673, 3243650, 3244675, 3243652, 3244677, 3243654, 3244679, 3243656, 3244681, 3243658, 3244683, 3243660, 3244685, 3244409, 3244415, 3244417, 3244419, 3244411, 3244450, 3243692, 3243702, 3244413, 3244281}].[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:45:18,501[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Make sure no other process is running on the device(s) while benchmarking.[0m
[DEVICE-ISOLATION-PROCESS][[36m2025-04-04 04:45:18,501[0m][[34mdevice-isolation[0m][[33mWARNING[0m] - Exiting device isolation process.[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:47:36,326[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Sending traceback to main process[0m
[ISOLATED-PROCESS][[36m2025-04-04 04:47:36,461[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[MAIN-PROCESS][[36m2025-04-04 04:47:37,940[0m][[34mprocess[0m][[32mINFO[0m] - 	+ Stopping device isolation process[0m
[MAIN-PROCESS][[36m2025-04-04 04:47:37,940[0m][[34mprocess[0m][[31mERROR[0m] - 	+ Received traceback from isolated process[0m
